# IDS 721 Project 3   Yuwei Zhang, Duke MIDS
### Cloud Map Reduce and Distributed Jobs

#### Background
AWS EMR(Elastic MapReduce) is a big data platform especially for processing huge amounts of data using common big data tools like Apache Spark, Hive, HBase and so on.
It's easy to set up EMR clusters and get data and resources from other AWS services such as S3.

The goal of the project is to run the basic Spark application "word count" on EMR.


#### Application
The application(Pi.py from <a href="https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbjBicmF6OTM0VUs1UmpqWUQ5bEpvT2ZBX3hNZ3xBQ3Jtc0traDJiOFFSb3NCdV9KN1dOamNlN0lta2pLWDdQZTVsWUUydHhJV0Fzbzl1OEFDd1lYWlctT2RlNGQwY2VJclRtRm9IeXgzcmhsRHBpUFhNOUJIRl85ekpkWkQwOGpBQ3J6cVdnMXpOUXJCOG10cFVIUQ&q=https%3A%2F%2Fgithub.com%2Fapache%2Fspark%2Fblob%2Fmaster%2Fexamples%2Fsrc%2Fmain%2Fpython%2Fpi.py"> Apach Spark </a>) will count the words from the designated file (text.txt).

In this project, an S3 bucket is created to store the input including spark script and file with text plus the output generated by the EMR automatically.

#### Potential problems during development
1. the input should be stored in S3
2. applications are given to the EMR cluster through "add steps"
3. remember to terminate the EMR service, corresponding EC2 instances, and delete S3 buckets after use
